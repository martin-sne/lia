\section{Literature review}
\label{relwork}
The creation of the HTTP/2 protocol have been discussed for many years. This section discusses the drawbacks of the previous version and presents the reasons why to move to a new protocol. The features that will improve the performance of the HTTP/2 protocol are also introduced. And finally the related work section will present the benchmarks that have been done for the SPDY and HTTP/2 protocol.

\subsection{HTTP/1.1 drawbacks}
Specified in multiple RFCs(7230-7235), HTTP/1.1 is a standard protocol for web-browsing that is now used for more than 15 years. This protocol has been reviewed a number of times and contains a high number of options. It uses a client-server model where the clients is most of the time a browser that is getting data from a server located in a different location. HTTP is the essence of the web and most of the users are using this protocol on a daily basis. 
Since the early beginning of the protocol, users complained about the time that takes a page to load. One big reason of this problem was not due to the protocol but to the speed and the reliability of the Internet. However the web has changed and more and more users have a high speed and reliable connection to the Internet. This and the growth of clients on the web has led to the increase of web pages size and the number of elements on a web page. HTTP was not designed for this use as indeed it is inadequately using the TCP protocol by retrieving one element from a web page using one TCP connection. It is thus not taking full advantage of the high performance TCP protocol as indeed the current use of TCP in HTTP/1.1 protocol can introduce problems that are leading to a slower loading time. These problems are for example the head of line blocking or the repetition of headers between multiple TCP sessions. The loading time is also highly dependent on the Round Trip Time (RTT) and some efforts have been done on improving this aspects over the years by adding geographical redundancy however the problem is still present for low cost organisation that are only able to develop server in a single location. 
This latency directly affect the clients and can be critical for your website (e.g. users leaving the page as it takes too long to load). So over the years, web developers have tried to reduce this critical factor that is latency. In order to do so the developers have been tried to adapt themselves to the protocol with workarounds that reduce the number of TCP connection. The most known workarounds are:
\begin{itemize}
\item Spriting: The fact to create an image containing many pictures destined to be present on the website and let the browsers display (via CSS or Javascript) the picture wanted by cropping/cutting out a single image.
\item Sharding: In order to overcome the problem of increasing TCP connections per domain, developers started to create several domains, holding different part of the website. This decreases the page loading time by reducing the number of connection per domain. Thus leading to a better performance of the HTTP/1.1 protocol. This method can also be used to allow more TCP sessions as each domains are bounded to a certain number.
\item Concatenation: In order to reduce the number of TCP connections, developers started to concatenate files (e.g. javascript) into one big files. 
\item Inlining: By embedding the data straight in the CSS in base64 format it avoids to send picture and thus creating new TCP connections. 
\end{itemize}
All these workarounds were needed as the page loading time and the number of requests were increasing so much that the web was slowing down even though more and more people had access to a reliable connection. After 15 years, it was time for a change. That is why the IETF created a working group named HTTPbis that started working on a new protocol. Beforehand Google started working on a new protocol, called SPDY, that was aiming to encounters the problems from the HTTP/1.1 protocol. The HTTPbis group started working from a working concept of protocol in the name of SPDY/3 (draft). And this was the start of HTTP/2.

\subsection{HTTP/2 improvements}
This section is subdivided into several ones describing the major improvements made from its predecessor HTTP/1.1 and emphasis on the reasons to move to the new HTTP/2 protocol for large scale environments. 

\subsubsection{Binary format}
HTTP/1.1 is based on a text/ascii format which is an advantage for humans to read and thus to debug the protocol. It is described by Raymond as "easy for human beings to read, write, and edit without specialized tools"(http://www.catb.org/esr/writings/taoup/html/ch05s01.html). However for computers such as clients and server, ascii is not their mother tongue. Indeed computers are using binary as a format for exchange. HTTP/2 is using this format.
"HTTP/2 also enables more efficient processing of messages through use of binary message framing."(https://datatracker.ietf.org/doc/draft-ietf-httpbis-http2/?include\_text=1) Binary is know to be much more efficient for binary structures. It is indeed hard to define the start and the end of a field in text based protocols. However with binary format it is much more natural. Binary will then improve the structure of the protocol and thus the efficiency of the protocol. In order to overcome the difficulty of debugging the binary protocol, tools such as curl have added support for HTTP/2 and Wireshark have created extensions to decode the network streams.

\subsubsection{Multiplexing and priority}
The use of streams is a major enhancement of the HTTP/2 protocol. A stream is described in the specification as "an independent, bi-directional sequence of frames exchanged between the client and server within an HTTP/2 connection." The stream identifier, present in the header format as an integer, will associate each frame belonging to the same stream. One HTTP/2 connection can contain several concurrently open stream, that can each be closed by the client or the server. Streams are multiplexed which can mean that they do not arrive at the same order as they have been sent. It is the role of the client to put this streams back together in a correct order to process the data. 
Each stream has a priority that can be set by the client in the HEADERS frame that opens the stream. This priority can be changed to re-prioritize a specific stream. This can permit to avoid the head of the line blocking and allow an endpoint to express how it would prefer to retrieve data when managing multiple concurrent streams.  A stream can also be dependent on other streams by setting the stream dependency parameter.

\subsubsection{Header compression}
One of the problem of HTTP/1.1 described earlier is that more and more elements are retrieved per web page. If too elements are close in type and location the headers will be very similar and "thus the redundant header fields in these requests unnecessarily consume bandwidth, measurably increasing latency. " (http://http2.github.io/http2-spec/compression.html) That is why header compression is a good solution to this problem. However HTTPS and the SPDY compression mechanism have been vulnerable to the BREACH and CRIME attacks. That is why the HTTPbis group has created HPACK (Header Compression), that is the specification that comes with HTTP/2. HPACK is described as "simple and inflexible." It eliminates redundant header fields and prevent security issues.

\subsubsection{Flow control}
The flow control is implemented in HTTP/2 by assigning an integer value to a window that will define how many octets of data the sender (server) is able to transmit. In that way the server is taking in consideration the buffering capacity of the receiver. This has enormous advantages as receivers on the web can be of different nature (e.g.Smartphones, laptop) with different connection. Flow control control can either operate on the entire connection or on each individual stream. The default value is 65535 octets. In order to reassign this value the receiver (client) can send a SETTINGS frame with his flow control integer value.

\subsubsection{Server push}
HTTP/2 allows the server to send extra information with a requested information required by a client. This functionality permits to increased the overall loading time by anticipating what the client will need before it asks for it. In that way the client will already possess the information when asking for it. This is called the server push mechanism. This mechanism is not required but can improve the user experience. The client must allow the server to do so. This allow the client to stay in control and indeed the client is able to terminate that pushed stream by sending a RST\_STREAM.

\subsection{Related work}
The new HTTP2 protocol has been based on the SPDY protocol developed mainly by Google. As shown by Google \cite{google2x}, the SPDY protocol meets its expectations by reducing the loading time of web pages by 55\%. Other people have tried to look into the protocol and one of the most interesting analysis has been done by Servy\cite{servy}. Servy evaluated the performance of the web servers implementing the SPDY protocol comparing it to HTTP/1.1 and HTTPS. The load testing tool used for this benchmark was the NeoLoad 4.1.2. His results showed that the implementation of SPDY increases by a factor of 6 the number concurrent of users possible before errors start showing up in comparison to HTTP and HTTPS. 
A contradictory study showing some boundaries of implementing SPDY has been done by Podjarny\cite{podiatry}. He shows that most of the websites use different domains and as SPDY works on a per-domain basis it does not necessarily help it to be faster. Finally, Wang et al.\cite{wang} have investigated the performance of SPDY for the improvements of the protocol compared to HTTP/1.1. This study highlights that SPDY is much faster since its benefits from the single TCP connection mechanism. However, they also mention that SPDY degrades under high packet loss compared to HTTP. 
Concerning the new standard HTTP/2 a few benchmarks have been performed by the creators of different client/server platforms. They reach the same conclusion for SPDY. \\
However, studies on comparisons between HTTP/2 (draft-ietf-httpbis-http2-14 \cite{h2c-14} ) and HTTP/1.1 with regards to concurrent clients and increasing amount of requests in different geographical locations and different page sizes or amount of elements a web page contains, have not been conducted yet.

\subsection{Conclusion}
To conclude, this section presented the reasons that have lead to the design of a new version of the HTTP protocol. The TCP protocol have been implemented in the early days of the HTTP protocol however due to the evolution of the web the protocol started lacking and the principal reason was that the use of the TCP protocol was not suiting the web usage any more. HTTP/2 address these issues by exploiting in a better way the TCP protocol. It also creates new features that will redesign the way to implement large infrastructure such as flow control, stream priority or server push. The new performance of the protocol have been tested by the designers of the implementation of the protocol but not by other parties. That is why this research has been conducted.